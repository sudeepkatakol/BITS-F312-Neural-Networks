{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Networks\n",
    "#### Source: CS231N, DeepLearning.ai\n",
    "\n",
    "## Neural Networks for Image data\n",
    "\n",
    "* Inspired by how we see and process images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hubel and Weisel Experiments (50s and 60s)\n",
    "\n",
    "\n",
    "### Topological Mapping\n",
    "\n",
    "* Nearby regions of image are processed by regions close to each other </center>\n",
    "\n",
    "<img src=\"./images/topological mapping.png\" width=\"300\"/>\n",
    "\n",
    "\n",
    "\n",
    "### Heirarchial organization\n",
    "\n",
    "\n",
    "* Cells work together in hierarchial way:\n",
    "    * Cells directly receiving the signal capturing low level information \n",
    "    * While those further away, build on the previous information and capture high level information.  \n",
    "\n",
    "\n",
    "* \n",
    "<div class=\"row\">\n",
    "  <div class=\"column\" style=\"float: left\">\n",
    "    <img src=\"./images/hubel.jpg\" width=\"600\"/>\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"./images/heirarchial organization.png\" width=\"200\"/>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporating the above idea into CNNs\n",
    "\n",
    "* We want our neurons to\n",
    " \n",
    "    * **Preserve spatial structure**: Neurons processing pixels close to each other should also be close to each other. Don't require neurons to look at the entire image. \n",
    "    \n",
    "    * **Maintain hierarchy**: Neurons should be able to harness information from previous layers and build upon them to get a better understanding of the image in the current layer and also help the next layer in understanding higher level features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Neural Networks\n",
    "\n",
    "\n",
    "<img src='./images/cnn.jpeg' width=\"800\"></img>\n",
    "\n",
    "\n",
    "* **Filters**: Trainable weights of CNN. Responsible for capturing higher level information from previous layer. Each filter looks for a certain quality in the image. Example: Edge --> Corner --> Shapes --> Face\n",
    "\n",
    "\n",
    "* **Convolution operation**:\n",
    "        \n",
    "    * Not accurate to call it convolution. In signal processing, it's called correlation.\n",
    "        \n",
    "    * Regular dot product operation.\n",
    "        \n",
    "<img src='./images/Convolution.png' width=\"800\"></img>\n",
    "\n",
    "<img src='./images/Convolution full.png' width=\"800\"></img>\n",
    "\n",
    "<img src='./images/Edge Detection.png' width=\"800\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/selection-1.jpg' width=\"800\"></img>\n",
    "<img src='./images/selection-2.jpg' width=\"800\"></img>\n",
    "<img src='./images/selection-3.jpg' width=\"800\"></img>\n",
    "<img src='./images/selection-4.jpg' width=\"800\"></img>\n",
    "<img src='./images/selection-5.jpg' width=\"800\"></img>\n",
    "<img src='./images/selection-6.jpg' width=\"800\"></img>\n",
    "<img src='./images/selection-7.jpg' width=\"800\"></img>\n",
    "<img src='./images/selection-8.jpg' width=\"800\"></img>\n",
    "<img src='./images/selection-9.jpg' width=\"800\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling and Strided Convolution\n",
    "\n",
    "### Pooling\n",
    "\n",
    "<img src=\"./images/pooling.jpeg\" width = \"400\"/>\n",
    "\n",
    "* Theoretical reasons\n",
    "\n",
    "    * Reduce redundancy of data.\n",
    "\n",
    "    * Prevent overfitting.\n",
    "\n",
    "    * Robust Features.\n",
    "    \n",
    "    * Signal processing.\n",
    "\n",
    "\n",
    "* Practical reason: Downsampling operation to reduce the number of parameters.\n",
    "\n",
    "### Strided convolution\n",
    "\n",
    "* Reduce redundancy by moving the filter by taking bigger steps across the image\n",
    "\n",
    "\n",
    "* Reduces the dimensionality of the next layer\n",
    "\n",
    "Note: The image is padded with zeros. This is done just to ensure the convolution operation (of given filter size and stride) is done correctly\n",
    "\n",
    "<img src='./images/convolution strided.gif'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNets\n",
    "\n",
    "* Conv, Activation, Pool -> Conv, Activation, Pool ...  -> Flatten -> Fully Connected Layer -> Softmax\n",
    "\n",
    "<img src='./images/convnet.jpeg' width=\"800\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Advantages of CNNs (Andrew Ng)\n",
    "\n",
    "#### Parameter Sharing\n",
    "\n",
    "* Feature detector which looks for a feature at one part of the image may be useful at someother region also.\n",
    "\n",
    "#### Sparsity of Connections \n",
    "\n",
    "* Few pixels (local area) are enough to judge the presence or absense of a feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But, Is my ConvNet learning what it's supposed to?\n",
    "\n",
    "http://cs231n.github.io/understanding-cnn/\n",
    "\n",
    "http://scs.ryerson.ca/~aharley/vis/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras_gpu_tensorflow]",
   "language": "python",
   "name": "conda-env-keras_gpu_tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
